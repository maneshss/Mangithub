{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2FtA8PLDOF"
      },
      "source": [
        "1.\tConduct your analysis using a cross-validation design.\n",
        "2.\tConduct / improve upon previous EDA.\n",
        "3.\tBuild the following models at a minimum.\n",
        "1.\tRandom Forest Classifier\n",
        "2.\tGradient Boosted Trees\n",
        "3.\tExtra Trees\n",
        "4.\tConduct hyperparameter tuning for the following at a minimum.\n",
        "1.\tn_estimators (number of trees)\n",
        "2.\tmax_features (maximum features considered for splitting a node)\n",
        "3.\tmax_depth (maximum number of levels in each tree)\n",
        "4.\tsplitting criteria (entropy or gini)\n",
        "5.\tCompare your models using the F1-Score on a 20% validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TUWd9pZEy8c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94ca9a9a"
      },
      "source": [
        "# Task\n",
        "Analyze the \"bank dataset\" from `/content/data.csv` by performing exploratory data analysis, preprocessing the data, and then training and comparing Random Forest Classifier, Gradient Boosted Trees, and Extra Trees models to predict a target variable. Evaluate models using the F1-Score, visualize their performance, and summarize findings with recommendations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9338135"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "### Subtask:\n",
        "Load the bank dataset from `/content/data.csv` into a pandas DataFrame and display the first few rows and basic information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb9c0ea3"
      },
      "source": [
        "**Reasoning**:\n",
        "First, I'll import the pandas library to work with DataFrames. Then, I'll load the data from the specified CSV file into a DataFrame named `df` and display its first few rows using `.head()` for a quick preview. Finally, I'll use `.info()` to get a summary of the DataFrame's structure, including column data types and non-null counts, which is crucial for initial data understanding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d870365e",
        "outputId": "1090c29f-db22-45fd-86cc-7c829c3b714f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "   Bankrupt?   ROA(C) before interest and depreciation before interest  \\\n",
            "0          1                                           0.370594          \n",
            "1          1                                           0.464291          \n",
            "2          1                                           0.426071          \n",
            "3          1                                           0.399844          \n",
            "4          1                                           0.465022          \n",
            "\n",
            "    ROA(A) before interest and % after tax  \\\n",
            "0                                 0.424389   \n",
            "1                                 0.538214   \n",
            "2                                 0.499019   \n",
            "3                                 0.451265   \n",
            "4                                 0.538432   \n",
            "\n",
            "    ROA(B) before interest and depreciation after tax  \\\n",
            "0                                           0.405750    \n",
            "1                                           0.516730    \n",
            "2                                           0.472295    \n",
            "3                                           0.457733    \n",
            "4                                           0.522298    \n",
            "\n",
            "    Operating Gross Margin   Realized Sales Gross Margin  \\\n",
            "0                 0.601457                      0.601457   \n",
            "1                 0.610235                      0.610235   \n",
            "2                 0.601450                      0.601364   \n",
            "3                 0.583541                      0.583541   \n",
            "4                 0.598783                      0.598783   \n",
            "\n",
            "    Operating Profit Rate   Pre-tax net Interest Rate  \\\n",
            "0                0.998969                    0.796887   \n",
            "1                0.998946                    0.797380   \n",
            "2                0.998857                    0.796403   \n",
            "3                0.998700                    0.796967   \n",
            "4                0.998973                    0.797366   \n",
            "\n",
            "    After-tax net Interest Rate   Non-industry income and expenditure/revenue  \\\n",
            "0                      0.808809                                      0.302646   \n",
            "1                      0.809301                                      0.303556   \n",
            "2                      0.808388                                      0.302035   \n",
            "3                      0.808966                                      0.303350   \n",
            "4                      0.809304                                      0.303475   \n",
            "\n",
            "   ...   Net Income to Total Assets   Total assets to GNP price  \\\n",
            "0  ...                     0.716845                    0.009219   \n",
            "1  ...                     0.795297                    0.008323   \n",
            "2  ...                     0.774670                    0.040003   \n",
            "3  ...                     0.739555                    0.003252   \n",
            "4  ...                     0.795016                    0.003878   \n",
            "\n",
            "    No-credit Interval   Gross Profit to Sales  \\\n",
            "0             0.622879                0.601453   \n",
            "1             0.623652                0.610237   \n",
            "2             0.623841                0.601449   \n",
            "3             0.622929                0.583538   \n",
            "4             0.623521                0.598782   \n",
            "\n",
            "    Net Income to Stockholder's Equity   Liability to Equity  \\\n",
            "0                             0.827890              0.290202   \n",
            "1                             0.839969              0.283846   \n",
            "2                             0.836774              0.290189   \n",
            "3                             0.834697              0.281721   \n",
            "4                             0.839973              0.278514   \n",
            "\n",
            "    Degree of Financial Leverage (DFL)  \\\n",
            "0                             0.026601   \n",
            "1                             0.264577   \n",
            "2                             0.026555   \n",
            "3                             0.026697   \n",
            "4                             0.024752   \n",
            "\n",
            "    Interest Coverage Ratio (Interest expense to EBIT)   Net Income Flag  \\\n",
            "0                                           0.564050                   1   \n",
            "1                                           0.570175                   1   \n",
            "2                                           0.563706                   1   \n",
            "3                                           0.564663                   1   \n",
            "4                                           0.575617                   1   \n",
            "\n",
            "    Equity to Liability  \n",
            "0              0.016469  \n",
            "1              0.020794  \n",
            "2              0.016474  \n",
            "3              0.023982  \n",
            "4              0.035490  \n",
            "\n",
            "[5 rows x 96 columns]\n",
            "\n",
            "Concise summary of the DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6819 entries, 0 to 6818\n",
            "Data columns (total 96 columns):\n",
            " #   Column                                                    Non-Null Count  Dtype  \n",
            "---  ------                                                    --------------  -----  \n",
            " 0   Bankrupt?                                                 6819 non-null   int64  \n",
            " 1    ROA(C) before interest and depreciation before interest  6819 non-null   float64\n",
            " 2    ROA(A) before interest and % after tax                   6819 non-null   float64\n",
            " 3    ROA(B) before interest and depreciation after tax        6819 non-null   float64\n",
            " 4    Operating Gross Margin                                   6819 non-null   float64\n",
            " 5    Realized Sales Gross Margin                              6819 non-null   float64\n",
            " 6    Operating Profit Rate                                    6819 non-null   float64\n",
            " 7    Pre-tax net Interest Rate                                6819 non-null   float64\n",
            " 8    After-tax net Interest Rate                              6819 non-null   float64\n",
            " 9    Non-industry income and expenditure/revenue              6819 non-null   float64\n",
            " 10   Continuous interest rate (after tax)                     6819 non-null   float64\n",
            " 11   Operating Expense Rate                                   6819 non-null   float64\n",
            " 12   Research and development expense rate                    6819 non-null   float64\n",
            " 13   Cash flow rate                                           6819 non-null   float64\n",
            " 14   Interest-bearing debt interest rate                      6819 non-null   float64\n",
            " 15   Tax rate (A)                                             6819 non-null   float64\n",
            " 16   Net Value Per Share (B)                                  6819 non-null   float64\n",
            " 17   Net Value Per Share (A)                                  6819 non-null   float64\n",
            " 18   Net Value Per Share (C)                                  6819 non-null   float64\n",
            " 19   Persistent EPS in the Last Four Seasons                  6819 non-null   float64\n",
            " 20   Cash Flow Per Share                                      6819 non-null   float64\n",
            " 21   Revenue Per Share (Yuan ¥)                               6819 non-null   float64\n",
            " 22   Operating Profit Per Share (Yuan ¥)                      6819 non-null   float64\n",
            " 23   Per Share Net profit before tax (Yuan ¥)                 6819 non-null   float64\n",
            " 24   Realized Sales Gross Profit Growth Rate                  6819 non-null   float64\n",
            " 25   Operating Profit Growth Rate                             6819 non-null   float64\n",
            " 26   After-tax Net Profit Growth Rate                         6819 non-null   float64\n",
            " 27   Regular Net Profit Growth Rate                           6819 non-null   float64\n",
            " 28   Continuous Net Profit Growth Rate                        6819 non-null   float64\n",
            " 29   Total Asset Growth Rate                                  6819 non-null   float64\n",
            " 30   Net Value Growth Rate                                    6819 non-null   float64\n",
            " 31   Total Asset Return Growth Rate Ratio                     6819 non-null   float64\n",
            " 32   Cash Reinvestment %                                      6819 non-null   float64\n",
            " 33   Current Ratio                                            6819 non-null   float64\n",
            " 34   Quick Ratio                                              6819 non-null   float64\n",
            " 35   Interest Expense Ratio                                   6819 non-null   float64\n",
            " 36   Total debt/Total net worth                               6819 non-null   float64\n",
            " 37   Debt ratio %                                             6819 non-null   float64\n",
            " 38   Net worth/Assets                                         6819 non-null   float64\n",
            " 39   Long-term fund suitability ratio (A)                     6819 non-null   float64\n",
            " 40   Borrowing dependency                                     6819 non-null   float64\n",
            " 41   Contingent liabilities/Net worth                         6819 non-null   float64\n",
            " 42   Operating profit/Paid-in capital                         6819 non-null   float64\n",
            " 43   Net profit before tax/Paid-in capital                    6819 non-null   float64\n",
            " 44   Inventory and accounts receivable/Net value              6819 non-null   float64\n",
            " 45   Total Asset Turnover                                     6819 non-null   float64\n",
            " 46   Accounts Receivable Turnover                             6819 non-null   float64\n",
            " 47   Average Collection Days                                  6819 non-null   float64\n",
            " 48   Inventory Turnover Rate (times)                          6819 non-null   float64\n",
            " 49   Fixed Assets Turnover Frequency                          6819 non-null   float64\n",
            " 50   Net Worth Turnover Rate (times)                          6819 non-null   float64\n",
            " 51   Revenue per person                                       6819 non-null   float64\n",
            " 52   Operating profit per person                              6819 non-null   float64\n",
            " 53   Allocation rate per person                               6819 non-null   float64\n",
            " 54   Working Capital to Total Assets                          6819 non-null   float64\n",
            " 55   Quick Assets/Total Assets                                6819 non-null   float64\n",
            " 56   Current Assets/Total Assets                              6819 non-null   float64\n",
            " 57   Cash/Total Assets                                        6819 non-null   float64\n",
            " 58   Quick Assets/Current Liability                           6819 non-null   float64\n",
            " 59   Cash/Current Liability                                   6819 non-null   float64\n",
            " 60   Current Liability to Assets                              6819 non-null   float64\n",
            " 61   Operating Funds to Liability                             6819 non-null   float64\n",
            " 62   Inventory/Working Capital                                6819 non-null   float64\n",
            " 63   Inventory/Current Liability                              6819 non-null   float64\n",
            " 64   Current Liabilities/Liability                            6819 non-null   float64\n",
            " 65   Working Capital/Equity                                   6819 non-null   float64\n",
            " 66   Current Liabilities/Equity                               6819 non-null   float64\n",
            " 67   Long-term Liability to Current Assets                    6819 non-null   float64\n",
            " 68   Retained Earnings to Total Assets                        6819 non-null   float64\n",
            " 69   Total income/Total expense                               6819 non-null   float64\n",
            " 70   Total expense/Assets                                     6819 non-null   float64\n",
            " 71   Current Asset Turnover Rate                              6819 non-null   float64\n",
            " 72   Quick Asset Turnover Rate                                6819 non-null   float64\n",
            " 73   Working capitcal Turnover Rate                           6819 non-null   float64\n",
            " 74   Cash Turnover Rate                                       6819 non-null   float64\n",
            " 75   Cash Flow to Sales                                       6819 non-null   float64\n",
            " 76   Fixed Assets to Assets                                   6819 non-null   float64\n",
            " 77   Current Liability to Liability                           6819 non-null   float64\n",
            " 78   Current Liability to Equity                              6819 non-null   float64\n",
            " 79   Equity to Long-term Liability                            6819 non-null   float64\n",
            " 80   Cash Flow to Total Assets                                6819 non-null   float64\n",
            " 81   Cash Flow to Liability                                   6819 non-null   float64\n",
            " 82   CFO to Assets                                            6819 non-null   float64\n",
            " 83   Cash Flow to Equity                                      6819 non-null   float64\n",
            " 84   Current Liability to Current Assets                      6819 non-null   float64\n",
            " 85   Liability-Assets Flag                                    6819 non-null   int64  \n",
            " 86   Net Income to Total Assets                               6819 non-null   float64\n",
            " 87   Total assets to GNP price                                6819 non-null   float64\n",
            " 88   No-credit Interval                                       6819 non-null   float64\n",
            " 89   Gross Profit to Sales                                    6819 non-null   float64\n",
            " 90   Net Income to Stockholder's Equity                       6819 non-null   float64\n",
            " 91   Liability to Equity                                      6819 non-null   float64\n",
            " 92   Degree of Financial Leverage (DFL)                       6819 non-null   float64\n",
            " 93   Interest Coverage Ratio (Interest expense to EBIT)       6819 non-null   float64\n",
            " 94   Net Income Flag                                          6819 non-null   int64  \n",
            " 95   Equity to Liability                                      6819 non-null   float64\n",
            "dtypes: float64(93), int64(3)\n",
            "memory usage: 5.0 MB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/data.csv')\n",
        "\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nConcise summary of the DataFrame:\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "276ba613"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)\n",
        "\n",
        "### Subtask:\n",
        "Conduct an in-depth exploratory data analysis (EDA). This will include checking for missing values, examining data types, generating descriptive statistics, and visualizing key distributions and relationships between features, focusing on potential target variables and relevant attributes for the bank dataset. This will also involve identifying categorical and numerical features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "346d3dad"
      },
      "source": [
        "**Reasoning**:\n",
        "The first step in the EDA is to standardize column names for easier access and consistency. I will create a function to clean column names by stripping whitespace and replacing special characters with underscores, then apply it to the DataFrame's columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "871674c5",
        "outputId": "2fe664bd-94f3-468d-d03f-a6ab38f96451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column names standardized.\n",
            "First 5 cleaned column names:\n",
            "['Bankrupt', 'ROA_C_before_interest_and_depreciation_before_interest', 'ROA_A_before_interest_and_after_tax', 'ROA_B_before_interest_and_depreciation_after_tax', 'Operating_Gross_Margin']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def clean_col_names(df):\n",
        "    cols = df.columns\n",
        "    new_cols = []\n",
        "    for col in cols:\n",
        "        # Remove leading/trailing spaces\n",
        "        new_col = col.strip()\n",
        "        # Replace spaces and special characters with underscores, keeping alphanumeric\n",
        "        new_col = re.sub(r'[^a-zA-Z0-9_]+', '_', new_col)\n",
        "        # Remove leading/trailing underscores that might result from cleaning\n",
        "        new_col = new_col.strip('_')\n",
        "        new_cols.append(new_col)\n",
        "    df.columns = new_cols\n",
        "    print(\"Column names standardized.\")\n",
        "    print(\"First 5 cleaned column names:\")\n",
        "    print(df.columns[:5].tolist())\n",
        "\n",
        "clean_col_names(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9a62a82"
      },
      "source": [
        "**Reasoning**:\n",
        "Even though `df.info()` showed no nulls, it is good practice to explicitly confirm the absence of missing values by summing `df.isnull()` across all columns to ensure data completeness.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec1f43ab",
        "outputId": "eaa3d746-be21-4c53-d302-a01dd6276448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total missing values across the DataFrame:\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "print(\"Total missing values across the DataFrame:\")\n",
        "print(df.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8a47acd"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that missing values have been confirmed as absent, the next step is to examine the target variable's distribution. I will identify the 'Bankrupt' column and use `value_counts()` to check its class balance, which is crucial for understanding the nature of the classification problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1342bcef",
        "outputId": "5bd9e463-2254-48b2-b18c-cb170461e99d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribution of the target variable 'Bankrupt':\n",
            "Bankrupt\n",
            "0    6599\n",
            "1     220\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentage distribution of the target variable 'Bankrupt':\n",
            "Bankrupt\n",
            "0    96.77372\n",
            "1     3.22628\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"Distribution of the target variable 'Bankrupt':\")\n",
        "print(df['Bankrupt'].value_counts())\n",
        "print(\"\\nPercentage distribution of the target variable 'Bankrupt':\")\n",
        "print(df['Bankrupt'].value_counts(normalize=True) * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed1eb10b"
      },
      "source": [
        "**Reasoning**:\n",
        "Following the instructions, the next step is to generate descriptive statistics for all numerical features to understand their central tendency, spread, and range, as specified in instruction 4 of the subtask.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2535bb4",
        "outputId": "7acf297b-5e76-4a95-eae0-ff1edefd6bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Descriptive statistics for numerical features:\n",
            "          Bankrupt  ROA_C_before_interest_and_depreciation_before_interest  \\\n",
            "count  6819.000000                                        6819.000000        \n",
            "mean      0.032263                                           0.505180        \n",
            "std       0.176710                                           0.060686        \n",
            "min       0.000000                                           0.000000        \n",
            "25%       0.000000                                           0.476527        \n",
            "50%       0.000000                                           0.502706        \n",
            "75%       0.000000                                           0.535563        \n",
            "max       1.000000                                           1.000000        \n",
            "\n",
            "       ROA_A_before_interest_and_after_tax  \\\n",
            "count                          6819.000000   \n",
            "mean                              0.558625   \n",
            "std                               0.065620   \n",
            "min                               0.000000   \n",
            "25%                               0.535543   \n",
            "50%                               0.559802   \n",
            "75%                               0.589157   \n",
            "max                               1.000000   \n",
            "\n",
            "       ROA_B_before_interest_and_depreciation_after_tax  \\\n",
            "count                                       6819.000000   \n",
            "mean                                           0.553589   \n",
            "std                                            0.061595   \n",
            "min                                            0.000000   \n",
            "25%                                            0.527277   \n",
            "50%                                            0.552278   \n",
            "75%                                            0.584105   \n",
            "max                                            1.000000   \n",
            "\n",
            "       Operating_Gross_Margin  Realized_Sales_Gross_Margin  \\\n",
            "count             6819.000000                  6819.000000   \n",
            "mean                 0.607948                     0.607929   \n",
            "std                  0.016934                     0.016916   \n",
            "min                  0.000000                     0.000000   \n",
            "25%                  0.600445                     0.600434   \n",
            "50%                  0.605997                     0.605976   \n",
            "75%                  0.613914                     0.613842   \n",
            "max                  1.000000                     1.000000   \n",
            "\n",
            "       Operating_Profit_Rate  Pre_tax_net_Interest_Rate  \\\n",
            "count            6819.000000                6819.000000   \n",
            "mean                0.998755                   0.797190   \n",
            "std                 0.013010                   0.012869   \n",
            "min                 0.000000                   0.000000   \n",
            "25%                 0.998969                   0.797386   \n",
            "50%                 0.999022                   0.797464   \n",
            "75%                 0.999095                   0.797579   \n",
            "max                 1.000000                   1.000000   \n",
            "\n",
            "       After_tax_net_Interest_Rate  \\\n",
            "count                  6819.000000   \n",
            "mean                      0.809084   \n",
            "std                       0.013601   \n",
            "min                       0.000000   \n",
            "25%                       0.809312   \n",
            "50%                       0.809375   \n",
            "75%                       0.809469   \n",
            "max                       1.000000   \n",
            "\n",
            "       Non_industry_income_and_expenditure_revenue  ...  \\\n",
            "count                                  6819.000000  ...   \n",
            "mean                                      0.303623  ...   \n",
            "std                                       0.011163  ...   \n",
            "min                                       0.000000  ...   \n",
            "25%                                       0.303466  ...   \n",
            "50%                                       0.303525  ...   \n",
            "75%                                       0.303585  ...   \n",
            "max                                       1.000000  ...   \n",
            "\n",
            "       Net_Income_to_Total_Assets  Total_assets_to_GNP_price  \\\n",
            "count                 6819.000000               6.819000e+03   \n",
            "mean                     0.807760               1.862942e+07   \n",
            "std                      0.040332               3.764501e+08   \n",
            "min                      0.000000               0.000000e+00   \n",
            "25%                      0.796750               9.036205e-04   \n",
            "50%                      0.810619               2.085213e-03   \n",
            "75%                      0.826455               5.269777e-03   \n",
            "max                      1.000000               9.820000e+09   \n",
            "\n",
            "       No_credit_Interval  Gross_Profit_to_Sales  \\\n",
            "count         6819.000000            6819.000000   \n",
            "mean             0.623915               0.607946   \n",
            "std              0.012290               0.016934   \n",
            "min              0.000000               0.000000   \n",
            "25%              0.623636               0.600443   \n",
            "50%              0.623879               0.605998   \n",
            "75%              0.624168               0.613913   \n",
            "max              1.000000               1.000000   \n",
            "\n",
            "       Net_Income_to_Stockholder_s_Equity  Liability_to_Equity  \\\n",
            "count                         6819.000000          6819.000000   \n",
            "mean                             0.840402             0.280365   \n",
            "std                              0.014523             0.014463   \n",
            "min                              0.000000             0.000000   \n",
            "25%                              0.840115             0.276944   \n",
            "50%                              0.841179             0.278778   \n",
            "75%                              0.842357             0.281449   \n",
            "max                              1.000000             1.000000   \n",
            "\n",
            "       Degree_of_Financial_Leverage_DFL  \\\n",
            "count                       6819.000000   \n",
            "mean                           0.027541   \n",
            "std                            0.015668   \n",
            "min                            0.000000   \n",
            "25%                            0.026791   \n",
            "50%                            0.026808   \n",
            "75%                            0.026913   \n",
            "max                            1.000000   \n",
            "\n",
            "       Interest_Coverage_Ratio_Interest_expense_to_EBIT  Net_Income_Flag  \\\n",
            "count                                       6819.000000           6819.0   \n",
            "mean                                           0.565358              1.0   \n",
            "std                                            0.013214              0.0   \n",
            "min                                            0.000000              1.0   \n",
            "25%                                            0.565158              1.0   \n",
            "50%                                            0.565252              1.0   \n",
            "75%                                            0.565725              1.0   \n",
            "max                                            1.000000              1.0   \n",
            "\n",
            "       Equity_to_Liability  \n",
            "count          6819.000000  \n",
            "mean              0.047578  \n",
            "std               0.050014  \n",
            "min               0.000000  \n",
            "25%               0.024477  \n",
            "50%               0.033798  \n",
            "75%               0.052838  \n",
            "max               1.000000  \n",
            "\n",
            "[8 rows x 96 columns]\n"
          ]
        }
      ],
      "source": [
        "print(\"Descriptive statistics for numerical features:\")\n",
        "print(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89af20c3"
      },
      "source": [
        "**Reasoning**:\n",
        "To analyze the correlation matrix with the target variable, I will first calculate the Pearson correlation coefficients between all features and the 'Bankrupt' column. Then, I will sort these correlations by their absolute values in descending order to identify the most relevant features and print the top 10 positive and negative correlations to gain insights into which features are most strongly related to bankruptcy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97a3da87",
        "outputId": "6a83778a-8656-4d64-cc7f-29fefc02d3c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Correlation with the target variable 'Bankrupt':\n",
            "Bankrupt                                                  1.000000\n",
            "Debt_ratio                                                0.250161\n",
            "Current_Liability_to_Assets                               0.194494\n",
            "Borrowing_dependency                                      0.176543\n",
            "Current_Liability_to_Current_Assets                       0.171306\n",
            "                                                            ...   \n",
            "ROA_C_before_interest_and_depreciation_before_interest   -0.260807\n",
            "ROA_B_before_interest_and_depreciation_after_tax         -0.273051\n",
            "ROA_A_before_interest_and_after_tax                      -0.282941\n",
            "Net_Income_to_Total_Assets                               -0.315457\n",
            "Net_Income_Flag                                                NaN\n",
            "Name: Bankrupt, Length: 96, dtype: float64\n",
            "\n",
            "Top 10 Positive Correlations with 'Bankrupt':\n",
            "Debt_ratio                             0.250161\n",
            "Current_Liability_to_Assets            0.194494\n",
            "Borrowing_dependency                   0.176543\n",
            "Current_Liability_to_Current_Assets    0.171306\n",
            "Liability_to_Equity                    0.166812\n",
            "Current_Liabilities_Equity             0.153828\n",
            "Current_Liability_to_Equity            0.153828\n",
            "Liability_Assets_Flag                  0.139212\n",
            "Total_expense_Assets                   0.139049\n",
            "Equity_to_Long_term_Liability          0.139014\n",
            "Name: Bankrupt, dtype: float64\n",
            "\n",
            "Top 10 Negative Correlations with 'Bankrupt':\n",
            "Per_Share_Net_profit_before_tax_Yuan                     -0.201395\n",
            "Net_profit_before_tax_Paid_in_capital                    -0.207857\n",
            "Retained_Earnings_to_Total_Assets                        -0.217779\n",
            "Persistent_EPS_in_the_Last_Four_Seasons                  -0.219560\n",
            "Net_worth_Assets                                         -0.250161\n",
            "ROA_C_before_interest_and_depreciation_before_interest   -0.260807\n",
            "ROA_B_before_interest_and_depreciation_after_tax         -0.273051\n",
            "ROA_A_before_interest_and_after_tax                      -0.282941\n",
            "Net_Income_to_Total_Assets                               -0.315457\n",
            "Net_Income_Flag                                                NaN\n",
            "Name: Bankrupt, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate correlations with the target variable\n",
        "correlations = df.corr(numeric_only=True)['Bankrupt'].sort_values(ascending=False)\n",
        "\n",
        "print(\"Correlation with the target variable 'Bankrupt':\")\n",
        "print(correlations)\n",
        "\n",
        "# Display top 10 positive correlations (excluding Bankrupt itself)\n",
        "print(\"\\nTop 10 Positive Correlations with 'Bankrupt':\")\n",
        "print(correlations[1:11])\n",
        "\n",
        "# Display top 10 negative correlations\n",
        "print(\"\\nTop 10 Negative Correlations with 'Bankrupt':\")\n",
        "print(correlations.tail(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf8c9603"
      },
      "source": [
        "**Reasoning**:\n",
        "To identify potential categorical features, I will first filter the DataFrame to include only integer columns, excluding the target variable 'Bankrupt'. Then, for each of these integer columns, I will check the number of unique values. If a column has only a few unique values, it is likely a categorical feature or a flag.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b3ea8ea",
        "outputId": "d4809076-1eff-4763-a116-d6bbd15de1a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identifying potential categorical features based on unique values in integer columns (excluding 'Bankrupt'):\n",
            "Column 'Liability_Assets_Flag': 2 unique values - [0, 1]\n",
            "  -> Likely a categorical feature or flag due to low number of unique values.\n",
            "Column 'Net_Income_Flag': 1 unique values - [1]\n",
            "  -> Likely a categorical feature or flag due to low number of unique values.\n"
          ]
        }
      ],
      "source": [
        "print(\"Identifying potential categorical features based on unique values in integer columns (excluding 'Bankrupt'):\")\n",
        "\n",
        "# Get all integer columns, excluding the target variable 'Bankrupt'\n",
        "integer_cols = df.select_dtypes(include=['int64']).columns.tolist()\n",
        "if 'Bankrupt' in integer_cols:\n",
        "    integer_cols.remove('Bankrupt')\n",
        "\n",
        "# Analyze unique values for each integer column\n",
        "for col in integer_cols:\n",
        "    unique_values = df[col].unique()\n",
        "    num_unique = len(unique_values)\n",
        "    print(f\"Column '{col}': {num_unique} unique values - {unique_values.tolist()}\")\n",
        "    if num_unique <= 5: # Threshold for considering a column potentially categorical or a flag\n",
        "        print(f\"  -> Likely a categorical feature or flag due to low number of unique values.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "136d1b70"
      },
      "source": [
        "## Data Preprocessing and Feature Engineering\n",
        "\n",
        "### Subtask:\n",
        "Perform necessary data preprocessing steps. This includes handling categorical features (e.g., one-hot encoding), scaling numerical features if appropriate, and any relevant feature engineering to prepare the data for machine learning models. Define the target variable.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a641b66"
      },
      "source": [
        "**Reasoning**:\n",
        "The 'Net_Income_Flag' column was identified as a constant feature in the previous EDA step, providing no predictive value. Therefore, I will drop this column to avoid issues in model training and reduce dimensionality.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d6f2f88",
        "outputId": "46dfa698-ec50-46fe-973c-469271d559f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropped 'Net_Income_Flag' column.\n",
            "New DataFrame shape: (6819, 95)\n"
          ]
        }
      ],
      "source": [
        "df = df.drop('Net_Income_Flag', axis=1)\n",
        "print(\"Dropped 'Net_Income_Flag' column.\")\n",
        "print(f\"New DataFrame shape: {df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bea1929"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the irrelevant column has been dropped, I will separate the features (X) from the target variable (y), which is 'Bankrupt', as per the instructions. Then, I will print the shapes of X and y to verify the separation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce26ced1",
        "outputId": "a3daafc2-9643-4039-9abf-5df82504548c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of features (X): (6819, 94)\n",
            "Shape of target (y): (6819,)\n"
          ]
        }
      ],
      "source": [
        "X = df.drop('Bankrupt', axis=1)\n",
        "y = df['Bankrupt']\n",
        "\n",
        "print(f\"Shape of features (X): {X.shape}\")\n",
        "print(f\"Shape of target (y): {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "538f7c71"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare the data for machine learning models, I will now identify the numerical features (excluding the binary 'Liability_Assets_Flag') and apply StandardScaler to them. This helps normalize the feature scales, which is crucial for many machine learning algorithms. I will also make sure to keep the original feature names after scaling and then print the first few rows of the scaled features to verify the transformation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5a0a9f3",
        "outputId": "d1ae841d-cc17-4e09-9b8b-7c4bda4ca75e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numerical features scaled using StandardScaler.\n",
            "First 5 rows of the scaled features (X):\n",
            "   ROA_C_before_interest_and_depreciation_before_interest  \\\n",
            "0                                          -2.217909        \n",
            "1                                          -0.673828        \n",
            "2                                          -1.303672        \n",
            "3                                          -1.735886        \n",
            "4                                          -0.661778        \n",
            "\n",
            "   ROA_A_before_interest_and_after_tax  \\\n",
            "0                            -2.045798   \n",
            "1                            -0.311068   \n",
            "2                            -0.908420   \n",
            "3                            -1.636209   \n",
            "4                            -0.307745   \n",
            "\n",
            "   ROA_B_before_interest_and_depreciation_after_tax  Operating_Gross_Margin  \\\n",
            "0                                         -2.400361               -0.383334   \n",
            "1                                         -0.598450                0.135068   \n",
            "2                                         -1.319910               -0.383759   \n",
            "3                                         -1.556340               -1.441418   \n",
            "4                                         -0.508050               -0.541238   \n",
            "\n",
            "   Realized_Sales_Gross_Margin  Operating_Profit_Rate  \\\n",
            "0                    -0.382638               0.016456   \n",
            "1                     0.136307               0.014671   \n",
            "2                    -0.388177               0.007858   \n",
            "3                    -1.441832              -0.004257   \n",
            "4                    -0.540708               0.016758   \n",
            "\n",
            "   Pre_tax_net_Interest_Rate  After_tax_net_Interest_Rate  \\\n",
            "0                  -0.023516                    -0.020165   \n",
            "1                   0.014799                     0.015966   \n",
            "2                  -0.061111                    -0.051183   \n",
            "3                  -0.017313                    -0.008676   \n",
            "4                   0.013703                     0.016186   \n",
            "\n",
            "   Non_industry_income_and_expenditure_revenue  \\\n",
            "0                                    -0.087479   \n",
            "1                                    -0.005957   \n",
            "2                                    -0.142238   \n",
            "3                                    -0.024491   \n",
            "4                                    -0.013254   \n",
            "\n",
            "   Continuous_interest_rate_after_tax  ...  Liability_Assets_Flag  \\\n",
            "0                           -0.031281  ...                      0   \n",
            "1                            0.009823  ...                      0   \n",
            "2                           -0.086566  ...                      0   \n",
            "3                           -0.011077  ...                      0   \n",
            "4                            0.013300  ...                      0   \n",
            "\n",
            "   Net_Income_to_Total_Assets  Total_assets_to_GNP_price  No_credit_Interval  \\\n",
            "0                   -2.254317                  -0.049491           -0.084274   \n",
            "1                   -0.309033                  -0.049491           -0.021388   \n",
            "2                   -0.820510                  -0.049491           -0.005984   \n",
            "3                   -1.691222                  -0.049491           -0.080226   \n",
            "4                   -0.316008                  -0.049491           -0.032052   \n",
            "\n",
            "   Gross_Profit_to_Sales  Net_Income_to_Stockholder_s_Equity  \\\n",
            "0              -0.383465                           -0.861611   \n",
            "1               0.135253                           -0.029804   \n",
            "2              -0.383698                           -0.249820   \n",
            "3              -1.441526                           -0.392864   \n",
            "4              -0.541255                           -0.029564   \n",
            "\n",
            "   Liability_to_Equity  Degree_of_Financial_Leverage_DFL  \\\n",
            "0             0.680171                         -0.060031   \n",
            "1             0.240685                         15.129816   \n",
            "2             0.679247                         -0.062961   \n",
            "3             0.093765                         -0.053903   \n",
            "4            -0.128014                         -0.178037   \n",
            "\n",
            "   Interest_Coverage_Ratio_Interest_expense_to_EBIT  Equity_to_Liability  \n",
            "0                                         -0.098978            -0.622067  \n",
            "1                                          0.364559            -0.535573  \n",
            "2                                         -0.125015            -0.621960  \n",
            "3                                         -0.052562            -0.471826  \n",
            "4                                          0.776395            -0.241715  \n",
            "\n",
            "[5 rows x 94 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Identify numerical columns to scale (all float64 columns, excluding binary int64)\n",
        "# 'Liability_Assets_Flag' is an int64 with 0/1 values, so it's already encoded and doesn't need scaling.\n",
        "numerical_cols = X.select_dtypes(include=['float64']).columns\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply scaling to numerical columns\n",
        "X[numerical_cols] = scaler.fit_transform(X[numerical_cols])\n",
        "\n",
        "print(\"Numerical features scaled using StandardScaler.\")\n",
        "print(\"First 5 rows of the scaled features (X):\")\n",
        "print(X.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3956dd12"
      },
      "source": [
        "## Data Splitting and Cross-validation Setup\n",
        "\n",
        "### Subtask:\n",
        "Split the preprocessed data into training and a 20% validation set. Set up a cross-validation strategy (e.g., K-Fold cross-validation) for hyperparameter tuning on the training set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f4cea8a"
      },
      "source": [
        "**Reasoning**:\n",
        "To begin the data splitting and cross-validation setup, I will import the necessary functions, `train_test_split` and `StratifiedKFold`, from `sklearn.model_selection`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad1ecb90",
        "outputId": "8cd1fe07-8915-46ab-f542-176f7ccc0997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imported train_test_split and StratifiedKFold.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "print(\"Imported train_test_split and StratifiedKFold.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32b0e087"
      },
      "source": [
        "**Reasoning**:\n",
        "I will split the preprocessed data into training and validation sets using `train_test_split` to allocate 20% for validation, ensuring class distribution is maintained by `stratify=y` and setting `random_state` for reproducibility. Then, I will initialize `StratifiedKFold` with `n_splits=5`, `shuffle=True`, and `random_state` for cross-validation on the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd989dcb",
        "outputId": "9020b65e-7f44-4ccc-92b8-5e534c2fb2c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (5455, 94)\n",
            "X_val shape: (1364, 94)\n",
            "y_train shape: (5455,)\n",
            "y_val shape: (1364,)\n",
            "\n",
            "StratifiedKFold cross-validation strategy initialized.\n"
          ]
        }
      ],
      "source": [
        "random_state_value = 42\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=random_state_value, stratify=y)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_val shape: {y_val.shape}\")\n",
        "\n",
        "# Initialize StratifiedKFold for cross-validation on the training set\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state_value)\n",
        "\n",
        "print(\"\\nStratifiedKFold cross-validation strategy initialized.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29d2d5a3"
      },
      "source": [
        "## Define Hyperparameter Grids\n",
        "\n",
        "### Subtask:\n",
        "Define comprehensive hyperparameter grids for Random Forest Classifier, Gradient Boosted Trees, and Extra Trees. This will include parameters such as 'n_estimators', 'max_features', 'max_depth', and 'criterion' ('gini' or 'entropy'), as specified in the problem description.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe3d5d93"
      },
      "source": [
        "**Reasoning**:\n",
        "I will import the required classifier classes from `sklearn.ensemble` to prepare for defining their hyperparameter grids.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5195fd9b",
        "outputId": "6b02f0ba-4aed-478c-f86d-71e9b3eaef02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imported RandomForestClassifier, GradientBoostingClassifier, and ExtraTreesClassifier.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
        "\n",
        "print(\"Imported RandomForestClassifier, GradientBoostingClassifier, and ExtraTreesClassifier.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ee01ea6"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the classifier classes are imported, I will define the hyperparameter grids for RandomForestClassifier, GradientBoostingClassifier, and ExtraTreesClassifier as specified in the instructions, and then print each grid for verification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8d1121c",
        "outputId": "7baa9bf7-cdc0-42fa-9372-7134285acc58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Classifier Hyperparameter Grid:\n",
            "{'n_estimators': [100, 200, 300], 'max_features': ['sqrt', 'log2'], 'max_depth': [10, 20, None], 'criterion': ['gini', 'entropy']}\n",
            "\n",
            "Gradient Boosting Classifier Hyperparameter Grid:\n",
            "{'n_estimators': [100, 200, 300], 'learning_rate': [0.05, 0.1, 0.2], 'max_depth': [3, 5, 7], 'subsample': [0.8, 0.9, 1.0]}\n",
            "\n",
            "Extra Trees Classifier Hyperparameter Grid:\n",
            "{'n_estimators': [100, 200, 300], 'max_features': ['sqrt', 'log2'], 'max_depth': [10, 20, None], 'criterion': ['gini', 'entropy']}\n"
          ]
        }
      ],
      "source": [
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "param_grid_et = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "print(\"Random Forest Classifier Hyperparameter Grid:\")\n",
        "print(param_grid_rf)\n",
        "print(\"\\nGradient Boosting Classifier Hyperparameter Grid:\")\n",
        "print(param_grid_gb)\n",
        "print(\"\\nExtra Trees Classifier Hyperparameter Grid:\")\n",
        "print(param_grid_et)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cecdc610"
      },
      "source": [
        "## Random Forest Classifier Training and Tuning\n",
        "\n",
        "### Subtask:\n",
        "Train and tune a Random Forest Classifier using the defined hyperparameter grid and the cross-validation setup. Evaluate its performance on the validation set using the F1-Score and identify the best model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0035a45e"
      },
      "source": [
        "**Reasoning**:\n",
        "To begin training and tuning the Random Forest Classifier, I will first import `GridSearchCV` for hyperparameter tuning and `f1_score` for model evaluation, as specified in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "199c2b65",
        "outputId": "25d4db9d-f1d6-4b20-f034-9a5a4fe4594e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imported GridSearchCV and f1_score.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "print(\"Imported GridSearchCV and f1_score.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84192618"
      },
      "source": [
        "**Reasoning**:\n",
        "I will instantiate a RandomForestClassifier, initialize GridSearchCV with the defined hyperparameter grid and cross-validation strategy, fit it to the training data, and then evaluate the best model's performance on the validation set using the F1-score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ddfb9d8",
        "outputId": "1da98928-d7fa-4cb8-88fe-559ac18965a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting GridSearchCV for Random Forest Classifier...\n",
            "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
            "\n",
            "Best parameters for Random Forest Classifier:\n",
            "{'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 100}\n",
            "Best F1-score on training set (cross-validation):\n",
            "0.24492609016999262\n",
            "\n",
            "F1-score of the best Random Forest model on the validation set: 0.2667\n"
          ]
        }
      ],
      "source": [
        "random_state_value = 4\n",
        "\n",
        "# Instantiate RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(random_state=random_state_value)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid_rf, cv=cv, scoring='f1', n_jobs=-1, verbose=1)\n",
        "\n",
        "print(\"Starting GridSearchCV for Random Forest Classifier...\")\n",
        "# Fit GridSearchCV to the training data\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest parameters for Random Forest Classifier:\")\n",
        "print(grid_search_rf.best_params_)\n",
        "print(\"Best F1-score on training set (cross-validation):\")\n",
        "print(grid_search_rf.best_score_)\n",
        "\n",
        "# Retrieve the best estimator\n",
        "best_rf_model = grid_search_rf.best_estimator_\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred_rf = best_rf_model.predict(X_val)\n",
        "\n",
        "# Calculate and print the F1-score on the validation set\n",
        "f1_rf_val = f1_score(y_val, y_pred_rf)\n",
        "print(f\"\\nF1-score of the best Random Forest model on the validation set: {f1_rf_val:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b0a6533"
      },
      "source": [
        "## Gradient Boosted Trees Training and Tuning\n",
        "\n",
        "### Subtask:\n",
        "Train and tune a Gradient Boosted Trees model using the defined hyperparameter grid and the cross-validation setup. Evaluate its performance on the validation set using the F1-Score and identify the best model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d63e79e"
      },
      "source": [
        "**Reasoning**:\n",
        "I will instantiate a GradientBoostingClassifier, initialize GridSearchCV with the defined hyperparameter grid and cross-validation strategy, fit it to the training data, and then evaluate the best model's performance on the validation set using the F1-score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72e6d730"
      },
      "source": [
        "# Task\n",
        "## Gradient Boosted Trees Training and Tuning\n",
        "\n",
        "### Subtask:\n",
        "Train and tune a Gradient Boosted Trees model using the *simplified* hyperparameter grid and the cross-validation setup. Evaluate its performance on the validation set using the F1-Score and identify the best model.\n",
        "\n",
        "**Reasoning**:\n",
        "The previous execution of Gradient Boosted Trees training was interrupted due to the extensive hyperparameter grid. To adhere to the plan's instruction of using a *simplified* grid to reduce tuning time, I will first redefine `param_grid_gb` with fewer options for each parameter: `n_estimators` (e.g., `[50, 100]`), `learning_rate` (e.g., `[0.1, 0.2]`), `max_depth` (e.g., `[3, 5]`), and `subsample` (e.g., `[0.8, 1.0]`). After redefining the grid, I will proceed to instantiate a GradientBoostingClassifier, initialize `GridSearchCV` with the new simplified grid and cross-validation strategy, fit it to the training data, and then evaluate the best model's performance on the validation set using the F1-score, as originally planned.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "869663f5"
      },
      "source": [
        "## Gradient Boosted Trees Training and Tuning\n",
        "\n",
        "### Subtask:\n",
        "Train and tune a Gradient Boosted Trees model using the *simplified* hyperparameter grid and the cross-validation setup. Evaluate its performance on the validation set using the F1-Score and identify the best model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc7278c8"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to train Gradient Boosted Trees was interrupted. As per the instructions, I will redefine the hyperparameter grid for Gradient Boosted Trees with simplified values to reduce computation time, then proceed with instantiating the model and performing GridSearchCV again.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "f62dbd9a",
        "outputId": "cbec3876-eeb0-4f4b-86bc-bd0341f731d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simplified Gradient Boosting Classifier Hyperparameter Grid:\n",
            "{'n_estimators': [50, 100], 'learning_rate': [0.1, 0.2], 'max_depth': [3, 5], 'subsample': [0.8, 1.0]}\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'GradientBoostingClassifier' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(param_grid_gb)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 3. Instantiate GradientBoostingClassifier\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m gb_model \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(random_state\u001b[38;5;241m=\u001b[39mrandom_state_value)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# 4. Initialize GridSearchCV\u001b[39;00m\n\u001b[1;32m     19\u001b[0m grid_search_gb \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mgb_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid_gb, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GradientBoostingClassifier' is not defined"
          ]
        }
      ],
      "source": [
        "random_state_value = 42\n",
        "\n",
        "# 1. Redefine the param_grid_gb dictionary with simplified hyperparameter values\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'learning_rate': [0.1, 0.2],\n",
        "    'max_depth': [3, 5],\n",
        "    'subsample': [0.8, 1.0]\n",
        "}\n",
        "\n",
        "# 2. Print the new param_grid_gb for verification\n",
        "print(\"Simplified Gradient Boosting Classifier Hyperparameter Grid:\")\n",
        "print(param_grid_gb)\n",
        "\n",
        "# 3. Instantiate GradientBoostingClassifier\n",
        "gb_model = GradientBoostingClassifier(random_state=random_state_value)\n",
        "\n",
        "# 4. Initialize GridSearchCV\n",
        "grid_search_gb = GridSearchCV(estimator=gb_model, param_grid=param_grid_gb, cv=2, scoring='f1', n_jobs=-1, verbose=1)\n",
        "\n",
        "print(\"\\nStarting GridSearchCV for Gradient Boosting Classifier with simplified grid...\")\n",
        "# 5. Fit GridSearchCV to the training data\n",
        "grid_search_gb.fit(X_train, y_train)\n",
        "\n",
        "# 6. Print the best parameters found by grid_search_gb\n",
        "print(\"\\nBest parameters for Gradient Boosting Classifier:\")\n",
        "print(grid_search_gb.best_params_)\n",
        "# 7. Print the best F1-score achieved on the training set during cross-validation\n",
        "print(\"Best F1-score on training set (cross-validation):\")\n",
        "print(grid_search_gb.best_score_)\n",
        "\n",
        "# 8. Retrieve the best estimator\n",
        "best_gb_model = grid_search_gb.best_estimator_\n",
        "\n",
        "# 9. Make predictions on the validation set\n",
        "y_pred_gb = best_gb_model.predict(X_val)\n",
        "\n",
        "# 10. Calculate and print the F1-score on the validation set\n",
        "f1_gb_val = f1_score(y_val, y_pred_gb)\n",
        "print(f\"\\nF1-score of the best Gradient Boosting model on the validation set: {f1_gb_val:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdb56c06"
      },
      "source": [
        "## Extra Trees Model Training and Tuning\n",
        "\n",
        "### Subtask:\n",
        "Train and tune an Extra Trees model using the defined hyperparameter grid and the cross-validation setup. Evaluate its performance on the validation set using the F1-Score and identify the best model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62fce195"
      },
      "source": [
        "## Extra Trees Model Training and Tuning\n",
        "\n",
        "### Subtask:\n",
        "Train and tune an Extra Trees model using the defined hyperparameter grid and the cross-validation setup. Evaluate its performance on the validation set using the F1-Score and identify the best model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9f8d382"
      },
      "source": [
        "**Reasoning**:\n",
        "To train and tune the Extra Trees model, I will instantiate an ExtraTreesClassifier, initialize GridSearchCV with its hyperparameter grid and the cross-validation strategy, fit it to the training data, and then evaluate the best model's performance on the validation set using the F1-score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "702dcd78",
        "outputId": "4e7ea141-6e97-4cfb-bd41-562fe1a38dfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting GridSearchCV for Extra Trees Classifier...\n",
            "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n",
            "\n",
            "Best parameters for Extra Trees Classifier:\n",
            "{'criterion': 'entropy', 'max_depth': 20, 'max_features': 'sqrt', 'n_estimators': 200}\n",
            "Best F1-score on training set (cross-validation):\n",
            "0.21062271062271062\n",
            "\n",
            "F1-score of the best Extra Trees model on the validation set: 0.2264\n"
          ]
        }
      ],
      "source": [
        "random_state_value = 42\n",
        "\n",
        "# Instantiate ExtraTreesClassifier\n",
        "et_model = ExtraTreesClassifier(random_state=random_state_value)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search_et = GridSearchCV(estimator=et_model, param_grid=param_grid_et, cv=2, scoring='f1', n_jobs=-1, verbose=1)\n",
        "\n",
        "print(\"Starting GridSearchCV for Extra Trees Classifier...\")\n",
        "# Fit GridSearchCV to the training data\n",
        "grid_search_et.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nBest parameters for Extra Trees Classifier:\")\n",
        "print(grid_search_et.best_params_)\n",
        "print(\"Best F1-score on training set (cross-validation):\")\n",
        "print(grid_search_et.best_score_)\n",
        "\n",
        "# Retrieve the best estimator\n",
        "best_et_model = grid_search_et.best_estimator_\n",
        "\n",
        "# Make predictions on the validation set\n",
        "y_pred_et = best_et_model.predict(X_val)\n",
        "\n",
        "# Calculate and print the F1-score on the validation set\n",
        "f1_et_val = f1_score(y_val, y_pred_et)\n",
        "print(f\"\\nF1-score of the best Extra Trees model on the validation set: {f1_et_val:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
